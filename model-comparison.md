# So S√°nh Chi Ti·∫øt Hai M√¥ H√¨nh CycleGAN cho Chuy·ªÉn ƒê·ªïi ·∫¢nh ƒê√™m sang Ban Ng√†y

## T√≥m T·∫Øt

B√†i vi·∫øt n√†y tr√¨nh b√†y ph√¢n t√≠ch so s√°nh chi ti·∫øt hai ph∆∞∆°ng ph√°p chuy·ªÉn ƒë·ªïi ·∫£nh ƒë√™m sang ·∫£nh ban ng√†y d·ª±a tr√™n ki·∫øn tr√∫c CycleGAN (Cycle-Consistent Generative Adversarial Networks). Hai ph∆∞∆°ng ph√°p ƒë∆∞·ª£c nghi√™n c·ª©u bao g·ªìm:

1. **CycleGAN v·ªõi ResNet Generator** - Ki·∫øn tr√∫c chu·∫©n s·ª≠ d·ª•ng Residual blocks
2. **Multi-Scale CycleGAN** - Ki·∫øn tr√∫c t√πy ch·ªânh v·ªõi multi-scale discriminator

C·∫£ hai m√¥ h√¨nh ƒë·ªÅu ƒë∆∞·ª£c hu·∫•n luy·ªán v√† ƒë√°nh gi√° tr√™n t·∫≠p d·ªØ li·ªáu BDD100K (Berkeley DeepDrive Dataset).

---

## 1. CycleGAN with ResNet Generator

### Ki·∫øn Tr√∫c M√¥ H√¨nh

![ResNet CycleGAN Architecture](images/resnet-cyclegan-architecture.png)
*H√¨nh 1: S∆° ƒë·ªì ki·∫øn tr√∫c t·ªïng th·ªÉ c·ªßa CycleGAN v·ªõi ResNet Generator*

#### Generator (ResNet-based U-Net)

**Th√¥ng s·ªë c∆° b·∫£n:**
- Input shape: `256√ó256√ó3`
- Base filters: `64`
- Ki·∫øn tr√∫c: Encoder-Decoder v·ªõi Residual blocks

**C·∫•u tr√∫c chi ti·∫øt:**

```
Input (256√ó256√ó3)
    ‚Üì
Reflection Padding + Conv2D(64, 7√ó7) + GroupNorm + ReLU
    ‚Üì
Downsampling (2 blocks)
‚îú‚îÄ Conv2D(128, 3√ó3, stride=2) + GroupNorm + ReLU
‚îî‚îÄ Conv2D(256, 3√ó3, stride=2) + GroupNorm + ReLU
    ‚Üì
Residual Blocks (9 blocks)
‚îú‚îÄ [ReflectionPad ‚Üí Conv2D ‚Üí GroupNorm ‚Üí ReLU]
‚îú‚îÄ [ReflectionPad ‚Üí Conv2D ‚Üí GroupNorm]
‚îî‚îÄ Add with input (skip connection)
    ‚Üì
Upsampling (2 blocks)
‚îú‚îÄ Conv2DTranspose(128, 3√ó3, stride=2) + GroupNorm + ReLU
‚îî‚îÄ Conv2DTranspose(64, 3√ó3, stride=2) + GroupNorm + ReLU
    ‚Üì
Reflection Padding + Conv2D(3, 7√ó7)
    ‚Üì
Tanh activation
    ‚Üì
Output (256√ó256√ó3) range: [-1, 1]
```

**ƒê·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t:**
- **Reflection Padding**: Gi·∫£m thi·ªÉu artifacts t·∫°i bi√™n ·∫£nh
- **Residual Blocks**: H·ªó tr·ª£ h·ªçc identity mapping v√† ·ªïn ƒë·ªãnh qu√° tr√¨nh hu·∫•n luy·ªán
- **GroupNormalization** (groups=-1): T∆∞∆°ng ƒë∆∞∆°ng v·ªõi Instance Normalization
- **Skip connections**: B·∫£o to√†n th√¥ng tin chi ti·∫øt t·ª´ encoder ƒë·∫øn decoder

#### Discriminator (PatchGAN)

**Th√¥ng s·ªë:**
- Base filters: `64`
- Kernel size: `4√ó4`
- Downsampling blocks: `3`

**C·∫•u tr√∫c:**

```
Input (256√ó256√ó3)
    ‚Üì
Conv2D(64, 4√ó4, stride=2) + LeakyReLU(0.2)
    ‚Üì
Conv2D(128, 4√ó4, stride=2) + GroupNorm + LeakyReLU(0.2)
    ‚Üì
Conv2D(256, 4√ó4, stride=2) + GroupNorm + LeakyReLU(0.2)
    ‚Üì
Conv2D(512, 4√ó4, stride=1) + GroupNorm + LeakyReLU(0.2)
    ‚Üì
Conv2D(1, 4√ó4, stride=1)
    ‚Üì
Output: Patch-based classification
```

**ƒê·∫∑c ƒëi·ªÉm:**
- **PatchGAN**: ƒê√°nh gi√° t√≠nh real/fake theo t·ª´ng patch thay v√¨ to√†n b·ªô ·∫£nh
- **LeakyReLU**: NgƒÉn ng·ª´a hi·ªán t∆∞·ª£ng dead neurons trong qu√° tr√¨nh hu·∫•n luy·ªán

### üéì Training Configuration

#### Loss Functions

```python
# 1. Generator Adversarial Loss
L_adv = MSE(ones, D(G(x)))

# 2. Cycle Consistency Loss (Œª_cycle = 10.0)
L_cycle = MAE(x, F(G(x))) + MAE(y, G(F(y)))
L_cycle_weighted = L_cycle √ó 10.0

# 3. Identity Loss (Œª_identity = 0.5)
L_identity = MAE(y, G(y)) + MAE(x, F(x))
L_identity_weighted = L_identity √ó 10.0 √ó 0.5

# 4. Total Generator Loss
L_G_total = L_adv + L_cycle_weighted + L_identity_weighted

# 5. Discriminator Loss
L_D = MSE(ones, D(real)) + MSE(zeros, D(fake))
```

#### Hyperparameters

| Parameter | Value |
|-----------|-------|
| **Batch Size** | 1 |
| **Image Size** | 256√ó256 |
| **Learning Rate** | 2e-4 |
| **Optimizer** | Adam (Œ≤‚ÇÅ=0.5, Œ≤‚ÇÇ=0.999) |
| **Epochs** | 100 |
| **Œª_cycle** | 10.0 |
| **Œª_identity** | 0.5 |
| **Dataset** | BDD100K |
| **Train samples** | 1200 per domain |
| **Test samples** | 400 per domain |

#### Data Preprocessing

```python
# Training augmentation
- Random horizontal flip
- Resize to 720√ó720
- Random crop to 256√ó256
- Normalize: (img/127.5) - 1

# Test preprocessing
- Resize to 256√ó256
- Normalize: (img/127.5) - 1
```

---

## 2. Multi-Scale CycleGAN

### Ki·∫øn Tr√∫c M√¥ H√¨nh

![Multi-Scale CycleGAN Architecture](images/multiscale-cyclegan-architecture.png)
*H√¨nh 2: S∆° ƒë·ªì ki·∫øn tr√∫c t·ªïng th·ªÉ c·ªßa Multi-Scale CycleGAN*

#### Generator (Custom U-Net with Inception Modules)

**Th√¥ng s·ªë c∆° b·∫£n:**
- Input shape: `256√ó256√ó3`
- Base filters: `16`
- Kernel size: `5√ó5` (to√†n b·ªô)
- Ki·∫øn tr√∫c: U-Net v·ªõi Inception modules

**Inception Module:**

```python
def inceptionModule(inputs, filter):
    x1 = Conv2D(filter, 5√ó5, dilation=1) ‚Üí Activation ‚Üí GroupNorm
    x2 = Conv2D(filter, 5√ó5, dilation=1) ‚Üí Activation ‚Üí GroupNorm
    x3 = Conv2D(filter, 5√ó5, dilation=1) ‚Üí Activation ‚Üí GroupNorm
    return x3
```

**C·∫•u tr√∫c Generator:**

```
Input (256√ó256√ó3)
    ‚Üì
Encoder Block 1: InceptionModule(16) ‚Üí MaxPool ‚Üí (128√ó128√ó16)
    ‚Üì skip1
Encoder Block 2: InceptionModule(32) ‚Üí MaxPool ‚Üí (64√ó64√ó32)
    ‚Üì skip2
Encoder Block 3: InceptionModule(64) ‚Üí MaxPool ‚Üí (32√ó32√ó64)
    ‚Üì skip3
Encoder Block 4: InceptionModule(128) ‚Üí MaxPool ‚Üí (16√ó16√ó128)
    ‚Üì skip4
Encoder Block 5: InceptionModule(256) ‚Üí MaxPool ‚Üí (8√ó8√ó256)
    ‚Üì skip5
Latent Space:
‚îú‚îÄ Flatten
‚îú‚îÄ Dense(128, L2=0.001) ‚Üê Bottleneck
‚îú‚îÄ Dense(8√ó8√ó256, L2=0.001)
‚îî‚îÄ Reshape(8√ó8√ó256)
    ‚Üì
Decoder Block 1: Upsample + skip5 + InceptionModule(256) ‚Üí (16√ó16√ó256)
    ‚Üì
Decoder Block 2: Upsample + skip4 + InceptionModule(128) ‚Üí (32√ó32√ó128)
    ‚Üì
Decoder Block 3: Upsample + skip3 + InceptionModule(64) ‚Üí (64√ó64√ó64)
    ‚Üì
Decoder Block 4: Upsample + skip2 + InceptionModule(32) ‚Üí (128√ó128√ó32)
    ‚Üì
Decoder Block 5: Upsample + skip1 + InceptionModule(16) ‚Üí (256√ó256√ó16)
    ‚Üì
Multi-scale Fusion:
‚îú‚îÄ Conv2DTranspose(16, stride=16) from Decoder Block 1
‚îî‚îÄ Concatenate with Decoder Block 5
    ‚Üì
Conv2DTranspose(3, 5√ó5, stride=1)
    ‚Üì
Sigmoid activation
    ‚Üì
Output (256√ó256√ó3) range: [0, 1]
```

**ƒê·∫∑c ƒëi·ªÉm n·ªïi b·∫•t:**
- **Inception Modules**: S·ª≠ d·ª•ng multiple convolutions ƒë·ªÉ h·ªçc c√°c ƒë·∫∑c tr∆∞ng phong ph√∫ h∆°n
- **Latent Bottleneck**: Dense layer v·ªõi 128 units v√† L2 regularization
- **Multi-scale Fusion**: K·∫øt h·ª£p ƒë·∫∑c tr∆∞ng t·ª´ c√°c decoder layers ·ªü ƒë·ªô s√¢u kh√°c nhau
- **Large Kernel (5√ó5)**: M·ªü r·ªông receptive field ƒë·ªÉ h·ªçc quan h·ªá kh√¥ng gian xa h∆°n

#### Discriminator (Multi-Scale PatchGAN)

**ƒê·∫∑c ƒëi·ªÉm ƒë·ªôc ƒë√°o:**
- **3 outputs ·ªü c√°c scales kh√°c nhau**: Cho ph√©p ƒë√°nh gi√° ·ªü multiple resolutions
- **Kernel size**: 5√ó5 (l·ªõn h∆°n kernel chu·∫©n 3√ó3 ho·∫∑c 4√ó4)

**C·∫•u tr√∫c:**

```
Input (256√ó256√ó3)
    ‚Üì
Encoder Block 1: InceptionModule(16) ‚Üí MaxPool ‚Üí (128√ó128√ó16)
    ‚Üì
Encoder Block 2: InceptionModule(32) ‚Üí MaxPool ‚Üí (64√ó64√ó32)
    ‚Üì
Encoder Block 3: InceptionModule(64) ‚Üí MaxPool ‚Üí (32√ó32√ó64) ‚îÄ‚îê
    ‚Üì                                                          ‚îÇ
Encoder Block 4: InceptionModule(128) ‚Üí MaxPool ‚Üí (16√ó16√ó128) ‚î§
    ‚Üì                                                          ‚îÇ
Encoder Block 5: InceptionModule(256) ‚Üí MaxPool ‚Üí (8√ó8√ó256)   ‚îÇ
    ‚Üì                                                          ‚Üì
Output 1: Conv2D(1, 5√ó5) ‚Üí (8√ó8√ó1)   ‚Üê Coarse scale (objects xa)
    ‚Üì                                                          ‚Üì
Output 2: Conv2D(1, 5√ó5) ‚Üí (16√ó16√ó1) ‚Üê Medium scale
    ‚Üì                                                          ‚Üì
Output 3: Conv2D(1, 5√ó5) ‚Üí (32√ó32√ó1) ‚Üê Fine scale (objects g·∫ßn)
```

**√ù nghƒ©a Multi-Scale:**
- **Scale 1 (8√ó8)**: ƒê√°nh gi√° t·ªïng th·ªÉ c·∫£nh quan v√† c√°c ƒë·ªëi t∆∞·ª£ng ·ªü kho·∫£ng c√°ch xa
- **Scale 2 (16√ó16)**: ƒê√°nh gi√° c√°c ƒë·ªëi t∆∞·ª£ng ·ªü kho·∫£ng c√°ch trung b√¨nh
- **Scale 3 (32√ó32)**: ƒê√°nh gi√° chi ti·∫øt c√°c ƒë·ªëi t∆∞·ª£ng ·ªü kho·∫£ng c√°ch g·∫ßn

**L·ª£i √≠ch:**

Discriminator c·∫ßn c√≥ kh·∫£ nƒÉng nh·∫≠n di·ªán c√°c ƒë·ªëi t∆∞·ª£ng ·ªü m·ªçi kho·∫£ng c√°ch trong ·∫£nh. Trong ng·ªØ c·∫£nh l√°i xe t·ª± ƒë·ªông, c√°c ƒë·ªëi t∆∞·ª£ng xu·∫•t hi·ªán ·ªü nhi·ªÅu kho·∫£ng c√°ch kh√°c nhau t·ª´ camera. Ki·∫øn tr√∫c multi-scale cho ph√©p discriminator ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng ·∫£nh sinh ra m·ªôt c√°ch hi·ªáu qu·∫£ ·ªü t·∫•t c·∫£ c√°c m·ª©c ƒë·ªô chi ti·∫øt.

### üéì Training Configuration

#### Loss Functions

```python
# Discriminator c√≥ 3 outputs ‚Üí 3 losses
L_D_source = MSE_scale1 + MSE_scale2 + MSE_scale3
L_D_target = MSE_scale1 + MSE_scale2 + MSE_scale3

# Generator adversarial loss (3 scales)
L_adv_target = MSE_scale1 + MSE_scale2 + MSE_scale3
L_adv_source = MSE_scale1 + MSE_scale2 + MSE_scale3

# Cycle consistency
L_cycle = MAE(x, F(G(x))) √ó 10 + MAE(y, G(F(y))) √ó 10

# Identity
L_identity = MAE(y, G(y)) √ó 0.5 + MAE(x, F(x)) √ó 0.5

# Total GAN loss
L_GAN_total = L_adv √ó 1 + L_cycle √ó 10 + L_identity √ó 0.5
```

**Loss weights:**
```python
loss_weights = [
    1, 1, 1,      # d_target_re scales 1,2,3
    1, 1, 1,      # d_source_re scales 1,2,3
    10, 10,       # cycle consistency (forward, backward)
    0.5, 0.5      # identity (source, target)
]
```

#### Hyperparameters

| Parameter | Value |
|-----------|-------|
| **Batch Size** | 4 |
| **Image Size** | 256√ó256 |
| **Learning Rate (Discriminator)** | 1e-4 |
| **Learning Rate (Generator)** | 5e-5 |
| **Optimizer** | Adam |
| **Weight Decay** | 6e-8 |
| **Epochs** | 30,000 |
| **Base Filters** | 16 |
| **Kernel Size** | 5√ó5 |
| **Dataset** | BDD100K |
| **Checkpoint Interval** | Every 2000 epochs |
| **Image Logging** | Every 1000 epochs |

#### Data Preprocessing

```python
# Simple preprocessing
- Resize to 256√ó256
- Normalize: img/255 (range [0,1])
```

#### Training v·ªõi Weights & Biases

```python
wandb.init(
    project="night2day-cyclegan",
    config={
        "epochs": 30000,
        "batch_size": 4,
        "learning_rate": 0.0001,
        "architecture": "Multi-Scale CycleGAN"
    }
)

# Tracked metrics
- Discriminator losses (source, target, 3 scales each)
- Generator losses (source, target, 3 scales each)
- Cycle consistency losses
- Identity losses
- Generated images every 1000 epochs
- Auto-backup checkpoints m·ªói 2000 epochs
```

**C√°c t√≠nh nƒÉng c·ªßa Weights & Biases:**
- Real-time loss tracking
- T·ª± ƒë·ªông l∆∞u checkpoints l√™n cloud
- Tr·ª±c quan h√≥a ·∫£nh ƒë∆∞·ª£c sinh ra
- T·ª± ƒë·ªông kh√¥i ph·ª•c training khi Kaggle timeout
- So s√°nh nhi·ªÅu l·∫ßn ch·∫°y th√≠ nghi·ªám

---

## So S√°nh Chi Ti·∫øt

![Architecture Comparison](images/architecture-comparison.png)
*H√¨nh 3: So s√°nh tr·ª±c quan gi·ªØa hai ki·∫øn tr√∫c CycleGAN*

### Ki·∫øn Tr√∫c

| Aspect | ResNet CycleGAN | Multi-Scale CycleGAN |
|--------|-----------------|----------------------|
| **Generator Base** | ResNet blocks | Inception modules |
| **Generator Filters** | 64 ‚Üí 256 | 16 ‚Üí 256 |
| **Generator Kernel** | 3√ó3, 4√ó4, 7√ó7 | 5√ó5 (uniform) |
| **Latent Space** | Kh√¥ng c√≥ | Dense(128) + L2 reg |
| **Multi-scale Fusion** | Kh√¥ng c√≥ | Skip t·ª´ deep decoder |
| **Output Activation** | tanh [-1,1] | sigmoid [0,1] |
| **Discriminator Type** | Single-scale PatchGAN | Multi-scale PatchGAN |
| **Discriminator Outputs** | 1 | 3 (scales: 8√ó8, 16√ó16, 32√ó32) |
| **Discriminator Kernel** | 4√ó4 | 5√ó5 |

### Training

| Aspect | ResNet CycleGAN | Multi-Scale CycleGAN |
|--------|-----------------|----------------------|
| **Batch Size** | 1 | 4 |
| **Learning Rate** | 2e-4 | 1e-4 (D), 5e-5 (G) |
| **Epochs** | 100 | 30,000 |
| **Training Time** | ~Few hours | ~Days/Weeks |
| **Data Augmentation** | Heavy (flip, crop) | Light (resize only) |
| **Normalization** | [-1, 1] | [0, 1] |
| **Optimizer** | Adam (Œ≤‚ÇÅ=0.5) | Adam (default Œ≤) |
| **Monitoring** | Manual callbacks | WandB cloud tracking |
| **Checkpointing** | Local only | Local + Cloud |

### Loss Functions

| Loss Component | ResNet CycleGAN | Multi-Scale CycleGAN |
|----------------|-----------------|----------------------|
| **Adversarial** | MSE | MSE (√ó3 scales) |
| **Cycle Consistency** | MAE √ó 10 | MAE √ó 10 |
| **Identity** | MAE √ó 5 | MAE √ó 0.5 |
| **Regularization** | Kh√¥ng c√≥ | L2 (0.001) trong latent space |
| **Total Losses** | 4 | 10 (3 scales √ó 2 + cycle + identity) |

---

## ∆Øu Nh∆∞·ª£c ƒêi·ªÉm

### ResNet CycleGAN

**∆Øu ƒëi·ªÉm:**
- **Ki·∫øn tr√∫c ƒë√£ ƒë∆∞·ª£c ch·ª©ng minh**: D·ª±a tr√™n c√°c nghi√™n c·ª©u ƒë√£ c√¥ng b·ªë v√† ki·ªÉm ch·ª©ng
- **Th·ªùi gian hu·∫•n luy·ªán ng·∫Øn**: Ch·ªâ c·∫ßn 100 epochs
- **·ªîn ƒë·ªãnh**: Residual blocks h·ªó tr·ª£ gradient flow hi·ªáu qu·∫£
- **Reflection padding**: Gi·∫£m thi·ªÉu artifacts t·∫°i bi√™n ·∫£nh
- **D·ªÖ tri·ªÉn khai**: Code ƒë∆°n gi·∫£n, d·ªÖ hi·ªÉu v√† b·∫£o tr√¨
- **Ti·∫øt ki·ªám t√†i nguy√™n**: Batch size 1, y√™u c·∫ßu RAM th·∫•p

**Nh∆∞·ª£c ƒëi·ªÉm:**
- **Single-scale discriminator**: H·∫°n ch·∫ø trong x·ª≠ l√Ω ƒë·ªëi t∆∞·ª£ng ·ªü nhi·ªÅu kho·∫£ng c√°ch kh√°c nhau
- **Data augmentation h·∫°n ch·∫ø**: ƒê·ªô ƒëa d·∫°ng d·ªØ li·ªáu ch∆∞a cao
- **Kh√¥ng c√≥ latent regularization**: Kh√¥ng √©p bu·ªôc h·ªçc compact representation
- **Th·ªùi gian hu·∫•n luy·ªán ng·∫Øn**: 100 epochs c√≥ th·ªÉ ch∆∞a ƒë·ªß ƒë·ªÉ ƒë·∫°t convergence t·ªëi ∆∞u

### Multi-Scale CycleGAN

**∆Øu ƒëi·ªÉm:**
- **Multi-scale discriminator**: X·ª≠ l√Ω hi·ªáu qu·∫£ c√°c ƒë·ªëi t∆∞·ª£ng ·ªü m·ªçi kho·∫£ng c√°ch
- **Large kernel (5√ó5)**: M·ªü r·ªông receptive field cho vi·ªác h·ªçc quan h·ªá kh√¥ng gian
- **Latent bottleneck**: √âp bu·ªôc h·ªçc compact v√† meaningful representation
- **Multi-scale fusion**: K·∫øt h·ª£p ƒë·∫∑c tr∆∞ng ·ªü nhi·ªÅu m·ª©c ƒë·ªô chi ti·∫øt
- **T√≠ch h·ª£p WandB**: Theo d√µi metrics, t·ª± ƒë·ªông kh√¥i ph·ª•c, sao l∆∞u cloud
- **Hu·∫•n luy·ªán k√©o d√†i**: 30,000 epochs ƒë·∫£m b·∫£o convergence t·ªët h∆°n
- **Batch size 4**: ∆Ø·ªõc l∆∞·ª£ng gradient ·ªïn ƒë·ªãnh h∆°n

**Nh∆∞·ª£c ƒëi·ªÉm:**
- **Th·ªùi gian hu·∫•n luy·ªán d√†i**: Y√™u c·∫ßu 30,000 epochs
- **Ph·ª©c t·∫°p**: Kh√≥ debug v√† c√≥ nhi·ªÅu hyperparameters c·∫ßn ƒëi·ªÅu ch·ªânh
- **Y√™u c·∫ßu t√†i nguy√™n cao**: C·∫ßn GPU m·∫°nh v√† th·ªùi gian hu·∫•n luy·ªán l√¢u
- **Nguy c∆° overfitting**: Training qu√° l√¢u c√≥ th·ªÉ d·∫´n ƒë·∫øn overfitting
- **3 discriminator outputs**: T√≠nh to√°n loss ph·ª©c t·∫°p h∆°n

---

## Thi·∫øt K·∫ø ƒê·∫∑c Bi·ªát cho B√†i To√°n Night-to-Day

### Tri·∫øt L√Ω Multi-Scale Discriminator

**V·∫•n ƒë·ªÅ:**

Trong ·∫£nh l√°i xe ban ƒë√™m, m·ªôt s·ªë ƒë·ªëi t∆∞·ª£ng c√≥ th·ªÉ r·∫•t t·ªëi do thi·∫øu √°nh s√°ng, ch·ªâ m·ªôt ph·∫ßn nh·ªè c·ªßa ƒë·ªëi t∆∞·ª£ng c√≥ th·ªÉ quan s√°t ƒë∆∞·ª£c. Discriminator c·∫ßn h·ªçc c√°ch ƒë√°nh gi√° ch√≠nh x√°c vi·ªác t√°i t·∫°o ƒë·ªëi t∆∞·ª£ng ban ng√†y t·ª´ th√¥ng tin h·∫°n ch·∫ø n√†y.

**Gi·∫£i ph√°p:**

1. **Kernel 5√ó5**: 
   - M·ªói pixel ƒë∆∞·ª£c ƒë√°nh gi√° v·ªõi context c·ªßa 24 neighbors (5√ó5-1)
   - H·ªçc ƒë∆∞·ª£c "pixel n√†y v·ªõi neighbors c·ªßa n√≥ c√≥ h·ª£p l√Ω kh√¥ng?"
   - T·ªët h∆°n kernel 3√ó3 cho vi·ªác reconstruct t·ª´ partial info

2. **3 Scales**:
   - **8√ó8 (coarse)**: Objects xa camera (xe ph√≠a xa, bi·ªÉn b√°o xa)
   - **16√ó16 (medium)**: Objects kho·∫£ng c√°ch trung b√¨nh
   - **32√ó32 (fine)**: Objects g·∫ßn camera (ƒë∆∞·ªùng ph√≠a tr∆∞·ªõc, xe ngay c·∫°nh)

3. **Inception Modules**:
   - 3 convolutions li√™n ti·∫øp ‚Üí h·ªçc features ·ªü multiple levels
   - K·∫øt h·ª£p v·ªõi 1√ó1 conv (residual) ‚Üí skip useless transformations

### Latent Space Regularization

```python
x = Flatten(conv5)
x = Dense(128, L2=0.001)  ‚Üê Force compact representation
x = Dense(original_size, L2=0.001)
x = Reshape(...)
```

**M·ª•c ƒë√≠ch:**
- Bu·ªôc model h·ªçc compact, meaningful representation
- Kh√¥ng cho ph√©p memorize patterns
- Generalization t·ªët h∆°n

---

## K·∫øt Qu·∫£ D·ª± Ki·∫øn

### ResNet CycleGAN
- **Th·ªùi gian hu·∫•n luy·ªán**: 2-4 gi·ªù (v·ªõi GPU)
- **Ch·∫•t l∆∞·ª£ng**: T·ªët, ƒë√°p ·ª©ng ƒë·ªß cho h·∫ßu h·∫øt c√°c tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng
- **·ª®ng d·ª•ng**: Prototyping, baseline, m√¥i tr∆∞·ªùng t√†i nguy√™n h·∫°n ch·∫ø

### Multi-Scale CycleGAN
- **Th·ªùi gian hu·∫•n luy·ªán**: V√†i ng√†y ƒë·∫øn v√†i tu·∫ßn
- **Ch·∫•t l∆∞·ª£ng**: Xu·∫•t s·∫Øc, chi ti·∫øt t·ªët cho ƒë·ªëi t∆∞·ª£ng ·ªü m·ªçi kho·∫£ng c√°ch
- **·ª®ng d·ª•ng**: Production, nghi√™n c·ª©u, khi y√™u c·∫ßu ch·∫•t l∆∞·ª£ng cao nh·∫•t

---

## Khuy·∫øn Ngh·ªã S·ª≠ D·ª•ng

### Khi n√†o n√™n s·ª≠ d·ª•ng ResNet CycleGAN?
- C·∫ßn k·∫øt qu·∫£ trong th·ªùi gian ng·∫Øn
- T√†i nguy√™n GPU h·∫°n ch·∫ø
- X√¢y d·ª±ng baseline model
- ·∫¢nh kh√¥ng ch·ª©a qu√° nhi·ªÅu ƒë·ªëi t∆∞·ª£ng ·ªü c√°c kho·∫£ng c√°ch kh√°c nhau

### Khi n√†o n√™n s·ª≠ d·ª•ng Multi-Scale CycleGAN?
- Y√™u c·∫ßu ch·∫•t l∆∞·ª£ng cao nh·∫•t
- C√≥ s·∫µn GPU m·∫°nh v√† th·ªùi gian hu·∫•n luy·ªán ƒë·ªß d√†i
- ·∫¢nh ch·ª©a nhi·ªÅu ƒë·ªëi t∆∞·ª£ng ·ªü c√°c scales kh√°c nhau (v√≠ d·ª•: c·∫£nh l√°i xe)
- Tri·ªÉn khai production
- M·ª•c ƒë√≠ch nghi√™n c·ª©u khoa h·ªçc

---

## Ph√¢n T√≠ch K·ªπ Thu·∫≠t

### GroupNormalization vs BatchNormalization

**L√Ω do s·ª≠ d·ª•ng GroupNormalization:**
- V·ªõi batch size = 1, BatchNormalization kh√¥ng ho·∫°t ƒë·ªông hi·ªáu qu·∫£
- GroupNorm v·ªõi groups=-1 t∆∞∆°ng ƒë∆∞∆°ng Instance Normalization
- Normalize t·ª´ng channel m·ªôt c√°ch ƒë·ªôc l·∫≠p
- Kh√¥ng ph·ª• thu·ªôc v√†o batch size

### Reflection Padding vs Zero Padding

**ResNet model s·ª≠ d·ª•ng Reflection Padding:**
```
Original: [1, 2, 3, 4, 5]
Zero Pad: [0, 0, 1, 2, 3, 4, 5, 0, 0]
Reflect:  [3, 2, 1, 2, 3, 4, 5, 4, 3]
```
**L·ª£i √≠ch:**
- Kh√¥ng t·∫°o artifacts t·∫°i bi√™n ·∫£nh
- ƒê·∫£m b·∫£o transitions m∆∞·ª£t m√†

### PatchGAN vs PixelGAN

**∆Øu ƒëi·ªÉm c·ªßa PatchGAN:**
- ƒê√°nh gi√° N√óN patches thay v√¨ to√†n b·ªô ·∫£nh
- S·ªë l∆∞·ª£ng tham s·ªë √≠t h∆°n
- Hi·ªáu qu·∫£ h∆°n cho c√°c chi ti·∫øt t·∫ßn s·ªë cao
- Hi·ªáu qu·∫£ v·ªÅ m·∫∑t t√≠nh to√°n

---

## T·∫≠p D·ªØ Li·ªáu: BDD100K

**Berkeley DeepDrive Dataset:**
- 100K diverse driving images
- Day/Night/Dawn/Dusk conditions
- Various weather conditions
- Urban/Highway/Residential areas

**Split trong c√°c models:**
- **ResNet**: 1200 train, 400 test (m·ªói domain)
- **Multi-Scale**: Full dataset, random sampling m·ªói batch

---



## T√†i Li·ªáu Tham Kh·∫£o

- **CycleGAN Paper**: "Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks" (Zhu et al., 2017)
- **ResNet Paper**: "Deep Residual Learning for Image Recognition" (He et al., 2016)
- **PatchGAN**: "Image-to-Image Translation with Conditional Adversarial Networks" (Isola et al., 2017)
- **BDD100K**: https://bdd-data.berkeley.edu/

---
